{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import tweepy\n",
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import configparser\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# login to twitter dev account\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "\n",
    "\n",
    "\n",
    "api_key = config['twitter']['api_key']\n",
    "api_key_secret = config['twitter']['api_key_secret']\n",
    "\n",
    "access_token = config['twitter']['access_token']\n",
    "access_token_secret = config['twitter']['access_token_secret']\n",
    "\n",
    "\n",
    "# aunthenticate\n",
    "\n",
    "auth = tweepy.OAuthHandler(api_key, api_key_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>favs</th>\n",
       "      <th>retweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HouseDemocrats</td>\n",
       "      <td>RT @RepJeffries: Heading back to Washington.\\n...</td>\n",
       "      <td>2022-01-10 16:58:01+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HouseDemocrats</td>\n",
       "      <td>American infrastructure was last modernized ov...</td>\n",
       "      <td>2022-01-10 14:30:01+00:00</td>\n",
       "      <td>139</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HouseDemocrats</td>\n",
       "      <td>RT @RepLoisFrankel: Sign up for ACA Marketplac...</td>\n",
       "      <td>2022-01-09 22:57:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HouseDemocrats</td>\n",
       "      <td>RT @HouseBudgetDems: .@POTUS is right. The GOP...</td>\n",
       "      <td>2022-01-09 21:40:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HouseDemocrats</td>\n",
       "      <td>RT @RepKirkpatrick: Good Employment News this ...</td>\n",
       "      <td>2022-01-09 18:53:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>HouseDemocrats</td>\n",
       "      <td>RT @WhiteHouse: Vaccine update: \\n2.2 million ...</td>\n",
       "      <td>2021-12-03 22:54:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>HouseDemocrats</td>\n",
       "      <td>BREAKING: Last month unemployment sunk‚¨áÔ∏è to th...</td>\n",
       "      <td>2021-12-03 22:18:00+00:00</td>\n",
       "      <td>198</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>HouseDemocrats</td>\n",
       "      <td>December dates to mark on your calendar üóì. \\n\\...</td>\n",
       "      <td>2021-12-03 21:28:00+00:00</td>\n",
       "      <td>95</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>HouseDemocrats</td>\n",
       "      <td>RT @WhiteHouse: Economic update:\\n- unemployme...</td>\n",
       "      <td>2021-12-03 20:00:19+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>HouseDemocrats</td>\n",
       "      <td>The math is CLEAR: the Child Tax Credit is cut...</td>\n",
       "      <td>2021-12-03 19:12:01+00:00</td>\n",
       "      <td>90</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               user                                               text  \\\n",
       "0    HouseDemocrats  RT @RepJeffries: Heading back to Washington.\\n...   \n",
       "1    HouseDemocrats  American infrastructure was last modernized ov...   \n",
       "2    HouseDemocrats  RT @RepLoisFrankel: Sign up for ACA Marketplac...   \n",
       "3    HouseDemocrats  RT @HouseBudgetDems: .@POTUS is right. The GOP...   \n",
       "4    HouseDemocrats  RT @RepKirkpatrick: Good Employment News this ...   \n",
       "..              ...                                                ...   \n",
       "195  HouseDemocrats  RT @WhiteHouse: Vaccine update: \\n2.2 million ...   \n",
       "196  HouseDemocrats  BREAKING: Last month unemployment sunk‚¨áÔ∏è to th...   \n",
       "197  HouseDemocrats  December dates to mark on your calendar üóì. \\n\\...   \n",
       "198  HouseDemocrats  RT @WhiteHouse: Economic update:\\n- unemployme...   \n",
       "199  HouseDemocrats  The math is CLEAR: the Child Tax Credit is cut...   \n",
       "\n",
       "                         date  favs  retweets  \n",
       "0   2022-01-10 16:58:01+00:00     0      1258  \n",
       "1   2022-01-10 14:30:01+00:00   139        40  \n",
       "2   2022-01-09 22:57:00+00:00     0        21  \n",
       "3   2022-01-09 21:40:00+00:00     0        41  \n",
       "4   2022-01-09 18:53:00+00:00     0        20  \n",
       "..                        ...   ...       ...  \n",
       "195 2021-12-03 22:54:00+00:00     0      2168  \n",
       "196 2021-12-03 22:18:00+00:00   198        60  \n",
       "197 2021-12-03 21:28:00+00:00    95        37  \n",
       "198 2021-12-03 20:00:19+00:00     0      2736  \n",
       "199 2021-12-03 19:12:01+00:00    90        37  \n",
       "\n",
       "[200 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Reality Check! \n",
    "## Pull 200 HouseDemocrat tweets to test connection\n",
    "posts = api.user_timeline(screen_name = \"HouseDemocrats\", count=200, tweet_mode=\"extended\")\n",
    "\n",
    "\n",
    "tweets = []\n",
    "columns=['user','text','date','favs','retweets']\n",
    "for tweet in posts:\n",
    "    tweets.append([tweet.user.screen_name, tweet.full_text, tweet.created_at, tweet.favorite_count, tweet.retweet_count])\n",
    "\n",
    "dftweets = pd.DataFrame(tweets, columns=columns)    \n",
    "dftweets\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "## functionalizing pull of more than 200 tweets using cursor\n",
    "\n",
    "def get_hist_Tweets(user):\n",
    "    \n",
    "    tweets = []\n",
    "    columns=['user','text','date','fav','rt']\n",
    "        \n",
    "    for tweet in tweepy.Cursor(api.user_timeline,screen_name=user).items(3200):\n",
    "        tweets.append([tweet.user.screen_name, \n",
    "                       tweet.text, \n",
    "                       tweet.created_at, \n",
    "                       tweet.favorite_count, \n",
    "                       tweet.retweet_count])\n",
    "    tempdf = pd.DataFrame(tweets, columns=columns)\n",
    "    return tempdf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "##tweets from Democrat Congresspeople and Senators\n",
    "Democrat_Users = ['POTUS',\n",
    "                  'SpeakerPelosi',\n",
    "                  'KamalaHarris',                  \n",
    "                  'VP',\n",
    "                  'JoeBiden',\n",
    "                  'RepAdamSchiff',\n",
    "                  'RepMaxineWaters',\n",
    "                  'IlhanMN',\n",
    "                  'SenSchumer',\n",
    "                  'SecretaryPete',\n",
    "                  'USDOT',\n",
    "                  'amyklobuchar',\n",
    "                  'staceyabrams',\n",
    "                  'Sen_JoeManchin',\n",
    "                  'SenSanders',\n",
    "                  'AOC',\n",
    "                  'SenatorDurbin',\n",
    "                  'DNC',\n",
    "                  'HouseDemocrats',\n",
    "                  'SenateDems',\n",
    "                  'harrisonjaime',\n",
    "                  'RepRaskin',\n",
    "                  'OversightDems',\n",
    "                  'RepMaloney',\n",
    "                  'WhiteHouse',\n",
    "                  'RashidaTlaib',\n",
    "                  'CoriBush',\n",
    "                  'PramilaJayapal']\n",
    "\n",
    "##tweets from Republican Congresspeople and Senators\n",
    "Republican_Users = ['Mike_Pence',\n",
    "                    'LeaderMcConnell',\n",
    "                    'LindseyGrahamSC',\n",
    "                    'marcorubio',\n",
    "                    'BillHagertyTN',\n",
    "                    'Hawley_MO',\n",
    "                    'GovRonDeSantis',\n",
    "                    'RepCawthorn',\n",
    "                    'Jim_Jordan',\n",
    "                    'SenTedCruz',\n",
    "                    'RepMattGaetz',\n",
    "                    'RepBoebert',\n",
    "                    'MarshaBlackburn',\n",
    "                    'JohnCornyn',\n",
    "                    'SenRonJohnson',\n",
    "                    'lisamurkowski',\n",
    "                    'SenatorCollins',\n",
    "                    'RepLizCheney',\n",
    "                    'MittRomney',\n",
    "                    'RNC',\n",
    "                    'RepGosar',\n",
    "                    'replouiegohmert',\n",
    "                    'MarkMeadows',\n",
    "                    'GOPLeader',\n",
    "                    'RandPaul',\n",
    "                    'GOPoversight',\n",
    "                    'GOP',\n",
    "                    'HouseGOP',\n",
    "                    'SenateGOP']\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all tweets from listed Dems  \n",
    "all_dem_tweets  = pd.DataFrame()#\n",
    "for dem in Democrat_Users:\n",
    "    temp_tweets = get_hist_Tweets(dem)\n",
    "    all_dem_tweets = pd.concat([all_dem_tweets,temp_tweets])\n",
    "\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all tweets from listed Gop\n",
    "all_gop_tweets  = pd.DataFrame()\n",
    "for gop in Republican_Users:\n",
    "    temp_tweets = get_hist_Tweets(gop)\n",
    "    all_gop_tweets = pd.concat([all_gop_tweets,temp_tweets])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 80947 entries, 0 to 3199\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype              \n",
      "---  ------  --------------  -----              \n",
      " 0   user    80947 non-null  object             \n",
      " 1   text    80947 non-null  object             \n",
      " 2   date    80947 non-null  datetime64[ns, UTC]\n",
      " 3   fav     80947 non-null  int64              \n",
      " 4   rt      80947 non-null  int64              \n",
      "dtypes: datetime64[ns, UTC](1), int64(2), object(2)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "all_dem_tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 75623 entries, 0 to 3199\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype              \n",
      "---  ------  --------------  -----              \n",
      " 0   user    75623 non-null  object             \n",
      " 1   text    75623 non-null  object             \n",
      " 2   date    75623 non-null  datetime64[ns, UTC]\n",
      " 3   fav     75623 non-null  object             \n",
      " 4   rt      75623 non-null  object             \n",
      "dtypes: datetime64[ns, UTC](1), object(4)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "all_gop_tweets.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting data as csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_gop_tweets.to_csv('data/gop_tweets.csv', sep='\\t', encoding='utf-8', index=False)\n",
    "all_dem_tweets.to_csv('data/dem_tweets.csv', sep='\\t', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_gop_tweets = pd.read_csv('data/gop_tweets.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Data Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    " \n",
    "def clean_tweet(tweet):\n",
    "    if type(tweet) == np.float:\n",
    "        return \"\"\n",
    "    temp = tweet.lower()\n",
    "    temp = re.sub(\"'\", \"\", temp) # to avoid removing contractions in english\n",
    "    temp = re.sub(\"@[A-Za-z0-9_]+\",\"\", temp)\n",
    "    temp = re.sub(\"#[A-Za-z0-9_]+\",\"\", temp)\n",
    "    temp = re.sub(r'http\\S+', '', temp)\n",
    "    temp = re.sub('[()!?]', ' ', temp)\n",
    "    temp = re.sub('\\[.*?\\]',' ', temp)\n",
    "    temp = re.sub(\"[^a-z0-9]\",\" \", temp)\n",
    "    temp = temp.split()\n",
    "    temp = [w for w in temp if not w in stopwords]\n",
    "    temp = \" \".join(word for word in temp)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = all_gop_tweets.head(20).copy()\n",
    "#test_df.rename(columns={'text':'tweet_txt'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20 entries, 0 to 19\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    20 non-null     object\n",
      "dtypes: object(1)\n",
      "memory usage: 288.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "tweets_df=test_df.loc[:,['text']]\n",
    "tweets_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @AmericanFreedom: https://t.co/8mElWdPaph https://t.co/Qul34SurDE\n",
      "\n",
      "https://t.co/9thARayoUw\n",
      "\n",
      "Two years ago today, US Forces carried out a drone strike killing the most dangerous terrorist in the world, Qasem‚Ä¶ https://t.co/igGWAwuYOV\n",
      "\n",
      "RT @AmericanFreedom: Pence group files SCOTUS brief opposing Biden vaccine mandate | @thehill  https://t.co/3f3rmXQDgn\n",
      "\n",
      "And Happy Birthday To My Amazing Wife ‚Å¶@KarenPence‚Å©! Her Love, Faith, Devotion to Our Family and Our Country Inspir‚Ä¶ https://t.co/zXH944I760\n",
      "\n",
      "Happy New Year America! Wishing You and Yours a Healthy and Prosperous 2022! üá∫üá∏\n",
      "\n",
      "RT @yaf: What. A. Year.\n",
      "\n",
      "We brought conservative ideas to BILLIONS online and tens of THOUSANDS in-person on campuses in 2021.\n",
      "\n",
      "And just wa‚Ä¶\n",
      "\n",
      "RT @yaf: Faith and freedom go hand in hand. @Mike_Pence https://t.co/9Xnlw0gWst\n",
      "\n",
      "RT @Mike_Pence: We Wish You A Merry Christmas! https://t.co/zQCP3sErTK\n",
      "\n",
      "We Wish You A Merry Christmas! https://t.co/zQCP3sErTK\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = 9\n",
    "for i in range(a,a+10):\n",
    "    print(tweets_df.text[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "def clean_text(text):\n",
    "    #''', , and '''\n",
    "#Make text lowercase   \n",
    "    text = text.lower()\n",
    "#remove text in square brackets\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "#remove punctuation   \n",
    "    text = re.sub(r'[%s]' % re.escape(string.punctuation), '', text) \n",
    "#remove words containing numbers\n",
    "    text = re.sub(r'\\w*\\d\\w*', '', text)\n",
    "    return text\n",
    "\n",
    "tweets_df_clean = pd.DataFrame(tweets_df.text.apply(lambda x: clean_text(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>us inflation hit  in december reaches fastest ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rt heritage senate democrats used to defend th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rt senategop rampant covid a crumbling economy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>on this national law enforcement appreciation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt senategop üö® jobs report üö®\\n\\neconomists pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rt americanfreedom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rt americanfreedom start the year off right an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>former vp mike pence asks supreme court to blo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rt americanfreedom joe biden‚Äôs vaccine mandate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rt americanfreedom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>two years ago today us forces carried out a dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>rt americanfreedom pence group files scotus br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>and happy birthday to my amazing wife ‚Å¶karenpe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>happy new year america wishing you and yours a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>rt yaf what a year\\n\\nwe brought conservative ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>rt yaf faith and freedom go hand in hand mikep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>rt mikepence we wish you a merry christmas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>we wish you a merry christmas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>rt dailysignal over a bleak backdrop american ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text\n",
       "0   us inflation hit  in december reaches fastest ...\n",
       "1   rt heritage senate democrats used to defend th...\n",
       "2   rt senategop rampant covid a crumbling economy...\n",
       "3   on this national law enforcement appreciation ...\n",
       "4   rt senategop üö® jobs report üö®\\n\\neconomists pre...\n",
       "5                                rt americanfreedom  \n",
       "6   rt americanfreedom start the year off right an...\n",
       "7   former vp mike pence asks supreme court to blo...\n",
       "8   rt americanfreedom joe biden‚Äôs vaccine mandate...\n",
       "9                                rt americanfreedom  \n",
       "10                                                   \n",
       "11  two years ago today us forces carried out a dr...\n",
       "12  rt americanfreedom pence group files scotus br...\n",
       "13  and happy birthday to my amazing wife ‚Å¶karenpe...\n",
       "14  happy new year america wishing you and yours a...\n",
       "15  rt yaf what a year\\n\\nwe brought conservative ...\n",
       "16  rt yaf faith and freedom go hand in hand mikep...\n",
       "17        rt mikepence we wish you a merry christmas \n",
       "18                     we wish you a merry christmas \n",
       "19  rt dailysignal over a bleak backdrop american ..."
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /Users/embernardo/opt/anaconda3/lib/python3.8/site-packages (3.0.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.3 in /Users/embernardo/opt/anaconda3/lib/python3.8/site-packages (from spacy) (2.0.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/embernardo/opt/anaconda3/lib/python3.8/site-packages (from spacy) (2.24.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /Users/embernardo/opt/anaconda3/lib/python3.8/site-packages (from spacy) (2.4.1)\n",
      "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in /Users/embernardo/opt/anaconda3/lib/python3.8/site-packages (from spacy) (1.7.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/embernardo/opt/anaconda3/lib/python3.8/site-packages (from spacy) (20.4)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /Users/embernardo/opt/anaconda3/lib/python3.8/site-packages (from spacy) (0.8.2)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /Users/embernardo/opt/anaconda3/lib/python3.8/site-packages (from spacy) (0.3.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /Users/embernardo/opt/anaconda3/lib/python3.8/site-packages (from spacy) (0.7.4)\n",
      "Requirement already satisfied: setuptools in /Users/embernardo/opt/anaconda3/lib/python3.8/site-packages (from spacy) (50.3.1.post20201107)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/embernardo/opt/anaconda3/lib/python3.8/site-packages (from spacy) (3.0.5)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /Users/embernardo/opt/anaconda3/lib/python3.8/site-packages (from spacy) (0.6.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/embernardo/opt/anaconda3/lib/python3.8/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.3 in /Users/embernardo/opt/anaconda3/lib/python3.8/site-packages (from spacy) (8.0.7)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/embernardo/opt/anaconda3/lib/python3.8/site-packages (from spacy) (1.19.2)\n",
      "Requirement already satisfied: jinja2 in /Users/embernardo/opt/anaconda3/lib/python3.8/site-packages (from spacy) (2.11.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.4 in /Users/embernardo/opt/anaconda3/lib/python3.8/site-packages (from spacy) (3.0.7)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/embernardo/opt/anaconda3/lib/python3.8/site-packages (from spacy) (4.50.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/embernardo/opt/anaconda3/lib/python3.8/site-packages (from spacy) (2.0.5)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/embernardo/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/embernardo/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/embernardo/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/embernardo/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.11)\n",
      "Requirement already satisfied: six in /Users/embernardo/opt/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->spacy) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/embernardo/opt/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in /Users/embernardo/opt/anaconda3/lib/python3.8/site-packages (from typer<0.4.0,>=0.3.0->spacy) (7.1.2)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /Users/embernardo/opt/anaconda3/lib/python3.8/site-packages (from pathy>=0.3.5->spacy) (5.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/embernardo/opt/anaconda3/lib/python3.8/site-packages (from jinja2->spacy) (1.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_core_web_sm\n",
    "\n",
    "nlp = en_core_web_sm.load()\n",
    "def lemmatizer(text):        \n",
    "    sent = []\n",
    "    doc = nlp(text)\n",
    "    for word in doc:\n",
    "        sent.append(word.lemma_)\n",
    "    return \" \".join(sent)\n",
    "tweets_df_clean = pd.DataFrame(tweets_df_clean.text.apply(lambda x: lemmatizer(x)))\n",
    "tweets_df_clean['text'] = tweets_df_clean['text'].str.replace('-PRON-', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>we inflation hit   in december reach fast pace...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rt heritage senate democrat use to defend the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rt senategop rampant covid a crumble economy c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>on this national law enforcement appreciation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt senategop üö® job report üö® \\n\\n economist pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rt americanfreedom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rt americanfreedom start the year off right an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>former vp mike penny ask supreme court to bloc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rt americanfreedom joe biden ‚Äôs vaccine mandat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rt americanfreedom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>two year ago today we force carry out a drone ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>rt americanfreedom penny group file scotus bri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>and happy birthday to my amazing wife ‚Å¶karenpe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>happy new year america wish you and yours a he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>rt yaf what a year \\n\\n we bring conservative ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>rt yaf faith and freedom go hand in hand mikep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>rt mikepence we wish you a merry christmas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>we wish you a merry christmas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>rt dailysignal over a bleak backdrop american ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text\n",
       "0   we inflation hit   in december reach fast pace...\n",
       "1   rt heritage senate democrat use to defend the ...\n",
       "2   rt senategop rampant covid a crumble economy c...\n",
       "3   on this national law enforcement appreciation ...\n",
       "4   rt senategop üö® job report üö® \\n\\n economist pre...\n",
       "5                                rt americanfreedom  \n",
       "6   rt americanfreedom start the year off right an...\n",
       "7   former vp mike penny ask supreme court to bloc...\n",
       "8   rt americanfreedom joe biden ‚Äôs vaccine mandat...\n",
       "9                                rt americanfreedom  \n",
       "10                                                   \n",
       "11  two year ago today we force carry out a drone ...\n",
       "12  rt americanfreedom penny group file scotus bri...\n",
       "13  and happy birthday to my amazing wife ‚Å¶karenpe...\n",
       "14  happy new year america wish you and yours a he...\n",
       "15  rt yaf what a year \\n\\n we bring conservative ...\n",
       "16  rt yaf faith and freedom go hand in hand mikep...\n",
       "17         rt mikepence we wish you a merry christmas\n",
       "18                      we wish you a merry christmas\n",
       "19  rt dailysignal over a bleak backdrop american ..."
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Unigrams\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "def get_top_n_words(corpus, n=None):\n",
    "    vec = CountVectorizer(stop_words='english').fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "common_words = get_top_n_words(tweets_df_clean.text, 10)\n",
    "unigram = pd.DataFrame(common_words, columns = ['unigram' , 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unigram</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rt</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>americanfreedom</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>american</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>biden</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>year</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mandate</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>wish</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>senategop</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>economy</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>job</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           unigram  count\n",
       "0               rt     12\n",
       "1  americanfreedom      5\n",
       "2         american      4\n",
       "3            biden      4\n",
       "4             year      4\n",
       "5          mandate      3\n",
       "6             wish      3\n",
       "7        senategop      2\n",
       "8          economy      2\n",
       "9              job      2"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "## bigrams\n",
    "def get_top_n_trigram(corpus, n=None):\n",
    "    vec = CountVectorizer(stop_words='english',ngram_range=(2,2)).fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in      vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "common_words = get_top_n_trigram(tweets_df_clean.text, 10)\n",
    "bigram = pd.DataFrame(common_words, columns = ['bigram' , 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rt americanfreedom</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rt senategop</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>biden vaccine</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vaccine mandate</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt yaf</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wish merry</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>merry christmas</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>inflation hit</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hit december</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>december reach</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               bigram  count\n",
       "0  rt americanfreedom      5\n",
       "1        rt senategop      2\n",
       "2       biden vaccine      2\n",
       "3     vaccine mandate      2\n",
       "4              rt yaf      2\n",
       "5          wish merry      2\n",
       "6     merry christmas      2\n",
       "7       inflation hit      1\n",
       "8        hit december      1\n",
       "9      december reach      1"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Trigrams\n",
    "def get_top_n_trigram(corpus, n=None):\n",
    "    vec = CountVectorizer(stop_words='english',ngram_range=(3,3)).fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in      vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "common_words = get_top_n_trigram(tweets_df_clean.text, 10)\n",
    "trigram = pd.DataFrame(common_words, columns = ['trigram' , 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trigram</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>biden vaccine mandate</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wish merry christmas</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>inflation hit december</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hit december reach</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>december reach fast</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>reach fast pace</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fast pace wsj</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rt heritage senate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>heritage senate democrat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>senate democrat use</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    trigram  count\n",
       "0     biden vaccine mandate      2\n",
       "1      wish merry christmas      2\n",
       "2    inflation hit december      1\n",
       "3        hit december reach      1\n",
       "4       december reach fast      1\n",
       "5           reach fast pace      1\n",
       "6             fast pace wsj      1\n",
       "7        rt heritage senate      1\n",
       "8  heritage senate democrat      1\n",
       "9       senate democrat use      1"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<20x6 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 22 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "vectorizer = CountVectorizer(\n",
    "    analyzer='word',       \n",
    "    min_df=3,# minimum required occurences of a word \n",
    "    stop_words='english',# remove stop words\n",
    "    lowercase=True,# convert all words to lowercase\n",
    "    token_pattern='[a-zA-Z0-9]{3,}',# num chars > 3\n",
    "    max_features=5000 # max number of unique words\n",
    "    )\n",
    "data_matrix = vectorizer.fit_transform(tweets_df_clean.text)\n",
    "data_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = LatentDirichletAllocation(\n",
    "n_components=10, # Number of topics\n",
    "learning_method='online',\n",
    "random_state=20,       \n",
    "n_jobs = -1  # Use all available CPUs\n",
    "                                     )\n",
    "lda_output = lda_model.fit_transform(data_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/embernardo/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "import_optional_dependency() got an unexpected keyword argument 'errors'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-d7f009eb6f97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msklearn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpyLDAvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlda_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tsne'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pyLDAvis/sklearn.py\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(lda_model, dtm, vectorizer, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \"\"\"\n\u001b[1;32m     94\u001b[0m     \u001b[0mopts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_extract_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlda_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pyLDAvis/_prepare.py\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(topic_term_dists, doc_topic_dists, doc_lengths, vocab, term_frequency, R, lambda_step, mds, n_jobs, plot_opts, sort_topics, start_index)\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0mdoc_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_series_with_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'doc_length'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_series_with_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'vocab'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m     \u001b[0m_input_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_term_dists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_topic_dists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterm_frequency\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m     \u001b[0mR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pyLDAvis/_prepare.py\u001b[0m in \u001b[0;36m_input_validate\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_input_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_input_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValidationError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m' * '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pyLDAvis/_prepare.py\u001b[0m in \u001b[0;36m_input_check\u001b[0;34m(topic_term_dists, doc_topic_dists, doc_lengths, vocab, term_frequency)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0merr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0m__num_dist_rows__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_term_dists\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mttds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0merr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Not all rows (distributions) in topic_term_dists sum to 1.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pyLDAvis/_prepare.py\u001b[0m in \u001b[0;36m__num_dist_rows__\u001b[0;34m(array, ndigits)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m__num_dist_rows__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndigits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/ops/common.py\u001b[0m in \u001b[0;36mnew_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     63\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/ops/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0;31m#  to avoid constructing two potentially large/sparse DataFrames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     join_columns, _, _ = left.columns.join(\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"outer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_indexers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m     )\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0mrvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_wrapped_if_datetimelike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     \u001b[0mrvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_from_zerodim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;31m# TODO: same for tuples?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36mna_arithmetic_op\u001b[0;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_na_arithmetic_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_cmp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \"\"\"\n\u001b[0;32m--> 140\u001b[0;31m     \u001b[0mReturn\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mresult\u001b[0m \u001b[0mof\u001b[0m \u001b[0mevaluating\u001b[0m \u001b[0mop\u001b[0m \u001b[0mon\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0mIf\u001b[0m \u001b[0mnative\u001b[0m \u001b[0mtypes\u001b[0m \u001b[0mare\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcompatible\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mtry\u001b[0m \u001b[0mcoercion\u001b[0m \u001b[0mto\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_typing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFuncType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomputation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNUMEXPR_INSTALLED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mroperator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/computation/check.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optional\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimport_optional_dependency\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mne\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimport_optional_dependency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"numexpr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"warn\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mNUMEXPR_INSTALLED\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mne\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mNUMEXPR_INSTALLED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: import_optional_dependency() got an unexpected keyword argument 'errors'"
     ]
    }
   ],
   "source": [
    "#!pip install pyLDAvis\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.sklearn.prepare(lda_model, data_matrix, vectorizer, mds='tsne')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/embernardo/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pandas in /Users/embernardo/opt/anaconda3/lib/python3.8/site-packages (1.3.5)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.3 in /Users/embernardo/opt/anaconda3/lib/python3.8/site-packages (from pandas) (2020.1)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /Users/embernardo/opt/anaconda3/lib/python3.8/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.17.3; platform_machine != \"aarch64\" and platform_machine != \"arm64\" and python_version < \"3.10\" in /Users/embernardo/opt/anaconda3/lib/python3.8/site-packages (from pandas) (1.22.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in /Users/embernardo/opt/anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stopwords' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-a37ca2b6b38c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mclean_tweet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtweets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-a37ca2b6b38c>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mclean_tweet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtweets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-bc5533e541df>\u001b[0m in \u001b[0;36mclean_tweet\u001b[0;34m(tweet)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[^a-z0-9]\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-bc5533e541df>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[^a-z0-9]\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stopwords' is not defined"
     ]
    }
   ],
   "source": [
    "results = [clean_tweet(tw) for tw in tweets]\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
