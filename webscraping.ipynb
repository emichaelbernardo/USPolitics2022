{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using NLP to Determine the 2022 U.S. Midterm Elections Political Platforms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# importing libraries\n",
    "\n",
    "import configparser\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "\n",
    "import tweepy\n",
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "new_stopwords = ['amp','biden','know','say','today','start','week','want','day','talk','new','thank','birthday','wish','happy','discuss']\n",
    "stopwords.extend(new_stopwords)\n",
    "\n",
    "import spacy \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction import text \n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(new_stopwords)\n",
    "\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "\n",
    "\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Twitter API connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# login to twitter dev account\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "\n",
    "\n",
    "\n",
    "api_key = config['twitter']['api_key']\n",
    "api_key_secret = config['twitter']['api_key_secret']\n",
    "\n",
    "access_token = config['twitter']['access_token']\n",
    "access_token_secret = config['twitter']['access_token_secret']\n",
    "\n",
    "\n",
    "# aunthenticate\n",
    "\n",
    "auth = tweepy.OAuthHandler(api_key, api_key_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reality Check! \n",
    "## Pull 200 HouseDemocrat tweets to test connection\n",
    "posts = api.user_timeline(screen_name = \"HouseDemocrats\", count=200, tweet_mode=\"extended\")\n",
    "\n",
    "\n",
    "tweets = []\n",
    "columns=['user','text','date','favs','retweets']\n",
    "for tweet in posts:\n",
    "    tweets.append([tweet.user.screen_name, tweet.full_text, tweet.created_at, tweet.favorite_count, tweet.retweet_count])\n",
    "\n",
    "dftweets = pd.DataFrame(tweets, columns=columns)    \n",
    "dftweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in list of congress twitter users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "senate = pd.read_excel(open('data/congress_twitter.xlsx', 'rb'),\n",
    "              sheet_name='Senate')  \n",
    "house = pd.read_excel(open('data/congress_twitter.xlsx', 'rb'),\n",
    "              sheet_name='House')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting all Dem accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "senate_dems = senate[senate['Party ']=='D']\n",
    "house_dems  = house[house['Party']=='D']\n",
    "all_dems_df = pd.concat([senate_dems,house_dems])\n",
    "\n",
    "\n",
    "all_dems_df = all_dems_df.drop(all_dems_df.columns[[2,3,4,5]], axis=1)  # df.columns is zero-based pd.Index\n",
    "all_dems_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dems_df['Party']='D' \n",
    "all_dems_df['Acct']= all_dems_df['Link'].str.replace('https://twitter.com/','',regex=True)\n",
    "all_dems_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting all GOP Accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "senate_gop = senate[senate['Party ']=='R']\n",
    "house_gop  = house[house['Party']=='R']\n",
    "all_gop_df = pd.concat([senate_gop,house_gop])\n",
    "\n",
    "\n",
    "all_gop_df = all_gop_df.drop(all_gop_df.columns[[2,3,4,5]], axis=1)  # df.columns is zero-based pd.Index\n",
    "all_gop_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_gop_df['Party']='R' \n",
    "all_gop_df['Acct'] = all_gop_df['Link'].str.replace('https://twitter.com/','',regex=True)\n",
    "all_gop_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create combined list of accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create combined list of accounts\n",
    "all_congress_accounts = pd.concat([all_gop_df,all_dems_df])\n",
    "all_congress_accounts.to_csv('data/cong_accounts.csv', encoding='utf-8', index=False)\n",
    "all_congress_accounts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get 1000 recent tweets from user\n",
    "\n",
    "def get_1k_Tweets(user):\n",
    "    \n",
    "    tweets = []\n",
    "    columns=['User','Content','Date','Favs','RTs']\n",
    "        \n",
    "    for tweet in tweepy.Cursor(api.user_timeline,screen_name=user).items(1000):\n",
    "        tweets.append([tweet.user.screen_name, \n",
    "                       tweet.text, \n",
    "                       tweet.created_at, \n",
    "                       tweet.favorite_count, \n",
    "                       tweet.retweet_count])\n",
    "    tempdf = pd.DataFrame(tweets, columns=columns)\n",
    "    return tempdf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_congress_tweets = pd.DataFrame()\n",
    "#all_congress_tweets  = pd.DataFrame()#\n",
    "no_accts = []\n",
    "for cong in tqdm(all_congress_accounts[214:].Acct):\n",
    "    try:\n",
    "        temp_tweets = get_1k_Tweets(cong)\n",
    "        all_congress_tweets = pd.concat([all_congress_tweets,temp_tweets])\n",
    "    except:\n",
    "        no_accts.append(cong)\n",
    "        print(f'{cong} account is not active or does not have tweets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_accts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_congress_tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_congress_tweets.to_csv('data/all_cong_tweets_01012021_01162022.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_congress_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_congress_accounts.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get Political Party and Name of account \n",
    "full_Cong_df = pd.merge(all_congress_tweets,all_congress_accounts, left_on='User', right_on='Acct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove redundant columns (link and Acct)\n",
    "full_Cong_df.drop(['Link','Acct'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_Cong_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write out full dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_Cong_df.to_csv('data/all_party_tweets_01012021_01162022.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_Cong_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 318055 entries, 0 to 318054\n",
      "Data columns (total 7 columns):\n",
      " #   Column   Non-Null Count   Dtype \n",
      "---  ------   --------------   ----- \n",
      " 0   User     314055 non-null  object\n",
      " 1   Content  318055 non-null  object\n",
      " 2   Date     318055 non-null  object\n",
      " 3   Favs     318055 non-null  int64 \n",
      " 4   RTs      318055 non-null  int64 \n",
      " 5   Name     318055 non-null  object\n",
      " 6   Party    318055 non-null  object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 17.0+ MB\n"
     ]
    }
   ],
   "source": [
    "all_congress_tweets = pd.read_csv('data/all_party_tweets_01012021_01162022.csv')\n",
    "all_congress_tweets.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restrict tweets to 2021-2022\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 266955 entries, 0 to 317693\n",
      "Data columns (total 7 columns):\n",
      " #   Column   Non-Null Count   Dtype \n",
      "---  ------   --------------   ----- \n",
      " 0   User     262955 non-null  object\n",
      " 1   Content  266955 non-null  object\n",
      " 2   Date     266955 non-null  object\n",
      " 3   Favs     266955 non-null  int64 \n",
      " 4   RTs      266955 non-null  int64 \n",
      " 5   Name     266955 non-null  object\n",
      " 6   Party    266955 non-null  object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 16.3+ MB\n"
     ]
    }
   ],
   "source": [
    "## Filter dates from 2021-2022\n",
    "\n",
    "start_date = '2021-01-01 00:00:00+00:00'\n",
    "end_date   = '2022-01-20 00:00:00+00:00'\n",
    "mask = (all_congress_tweets['Date'] > start_date) & (all_congress_tweets['Date'] <= end_date)\n",
    "\n",
    "all_tweets= all_congress_tweets.loc[mask]\n",
    "all_tweets.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate Dem and GOP Tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 38782 entries, 0 to 53963\n",
      "Data columns (total 7 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   User     34782 non-null  object\n",
      " 1   Content  38782 non-null  object\n",
      " 2   Date     38782 non-null  object\n",
      " 3   Favs     38782 non-null  int64 \n",
      " 4   RTs      38782 non-null  int64 \n",
      " 5   Name     38782 non-null  object\n",
      " 6   Party    38782 non-null  object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "just_gop_df = all_tweets[all_tweets.Party=='R']\n",
    "just_gop_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 228173 entries, 54128 to 317693\n",
      "Data columns (total 7 columns):\n",
      " #   Column   Non-Null Count   Dtype \n",
      "---  ------   --------------   ----- \n",
      " 0   User     228173 non-null  object\n",
      " 1   Content  228173 non-null  object\n",
      " 2   Date     228173 non-null  object\n",
      " 3   Favs     228173 non-null  int64 \n",
      " 4   RTs      228173 non-null  int64 \n",
      " 5   Name     228173 non-null  object\n",
      " 6   Party    228173 non-null  object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 13.9+ MB\n"
     ]
    }
   ],
   "source": [
    "just_dem_df = all_tweets[all_tweets.Party=='D']\n",
    "just_dem_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testdf = all_tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emoji(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\U00010000-\\U0010ffff\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u200d\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\ufe0f\"  # dingbats\n",
    "                               u\"\\u3030\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string)\n",
    "\n",
    "\n",
    "def removeRT(text):\n",
    "    RTless = lambda x: re.compile(r'\\#').sub('', re.compile('RT @').sub('@', x, count=1).strip())\n",
    "    return (RTless(text))\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove RT\n",
    "    text = removeRT(text)\n",
    "    \n",
    "    # Remove emojis\n",
    "    text = remove_emoji(text)\n",
    "\n",
    "    #Make text lowercase   \n",
    "    text = text.lower()\n",
    "    \n",
    "    #remove text in square brackets\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "    \n",
    "    #remove punctuation   \n",
    "    text = re.sub(r'[%s]' % re.escape(string.punctuation), '', text) \n",
    "    \n",
    "    #remove words containing numbers\n",
    "    text = re.sub(r'\\w*\\d\\w*', '', text)\n",
    "    \n",
    "\n",
    "    \n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testdf_clean = pd.DataFrame(testdf.Content.apply(lambda x: clean_text(x)))\n",
    "#testdf_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54128</th>\n",
       "      <td>one wisconsin senator me voted to deliver  mil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54129</th>\n",
       "      <td>this is a horrible tragedy that demands a thor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54130</th>\n",
       "      <td>i am proud to announce that wisconsin is recei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54131</th>\n",
       "      <td>reshadhudson senatorbaldwin reacts to supreme ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54132</th>\n",
       "      <td>shout out to milwaukees bronzeville neighborho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317689</th>\n",
       "      <td>is also bringing us the continued dominance o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317690</th>\n",
       "      <td>congratulations to ukfootball on their taxslay...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317691</th>\n",
       "      <td>i feel compelled to note that the senate major...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317692</th>\n",
       "      <td>if mitch doesn’t want to send out  checks to a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317693</th>\n",
       "      <td>wishing everyone a happy healthy and peaceful ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>228173 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Content\n",
       "54128   one wisconsin senator me voted to deliver  mil...\n",
       "54129   this is a horrible tragedy that demands a thor...\n",
       "54130   i am proud to announce that wisconsin is recei...\n",
       "54131   reshadhudson senatorbaldwin reacts to supreme ...\n",
       "54132   shout out to milwaukees bronzeville neighborho...\n",
       "...                                                   ...\n",
       "317689   is also bringing us the continued dominance o...\n",
       "317690  congratulations to ukfootball on their taxslay...\n",
       "317691  i feel compelled to note that the senate major...\n",
       "317692  if mitch doesn’t want to send out  checks to a...\n",
       "317693  wishing everyone a happy healthy and peaceful ...\n",
       "\n",
       "[228173 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Clean Dem Tweets\n",
    "dem_clean = pd.DataFrame(just_dem_df.Content.apply(lambda x: clean_text(x)))\n",
    "dem_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>biden let illegal immigrants enter our country...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>if youre in a position to donate blood please ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the biden admin is sitting on  covid tests whi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>biden had the audacity to go on a reckless spe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gopoversight dr fauci shut down debate about t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53959</th>\n",
       "      <td>pursuant to the us constitution state legislat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53960</th>\n",
       "      <td>in battleground states signature verification ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53961</th>\n",
       "      <td>usarmy selfless service  \\n\\nsunrise at arling...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53962</th>\n",
       "      <td>richardgrenell washington is so out of touch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53963</th>\n",
       "      <td>wishing you and your loved ones a happy and sa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38782 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Content\n",
       "0      biden let illegal immigrants enter our country...\n",
       "1      if youre in a position to donate blood please ...\n",
       "2      the biden admin is sitting on  covid tests whi...\n",
       "3      biden had the audacity to go on a reckless spe...\n",
       "4      gopoversight dr fauci shut down debate about t...\n",
       "...                                                  ...\n",
       "53959  pursuant to the us constitution state legislat...\n",
       "53960  in battleground states signature verification ...\n",
       "53961  usarmy selfless service  \\n\\nsunrise at arling...\n",
       "53962       richardgrenell washington is so out of touch\n",
       "53963  wishing you and your loved ones a happy and sa...\n",
       "\n",
       "[38782 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Clean Gop Tweets\n",
    "gop_clean = pd.DataFrame(just_gop_df.Content.apply(lambda x: clean_text(x)))\n",
    "gop_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>biden let illegal immigrants enter our country...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>if youre in a position to donate blood please ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the biden admin is sitting on  covid tests whi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>biden had the audacity to go on a reckless spe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gopoversight dr fauci shut down debate about t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317689</th>\n",
       "      <td>is also bringing us the continued dominance o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317690</th>\n",
       "      <td>congratulations to ukfootball on their taxslay...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317691</th>\n",
       "      <td>i feel compelled to note that the senate major...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317692</th>\n",
       "      <td>if mitch doesn’t want to send out  checks to a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317693</th>\n",
       "      <td>wishing everyone a happy healthy and peaceful ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>266955 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Content\n",
       "0       biden let illegal immigrants enter our country...\n",
       "1       if youre in a position to donate blood please ...\n",
       "2       the biden admin is sitting on  covid tests whi...\n",
       "3       biden had the audacity to go on a reckless spe...\n",
       "4       gopoversight dr fauci shut down debate about t...\n",
       "...                                                   ...\n",
       "317689   is also bringing us the continued dominance o...\n",
       "317690  congratulations to ukfootball on their taxslay...\n",
       "317691  i feel compelled to note that the senate major...\n",
       "317692  if mitch doesn’t want to send out  checks to a...\n",
       "317693  wishing everyone a happy healthy and peaceful ...\n",
       "\n",
       "[266955 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Clean all combined tweets\n",
    "all_tweets_clean = pd.DataFrame(all_tweets.Content.apply(lambda x: clean_text(x)))\n",
    "all_tweets_clean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization to get word roots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lemmatization \n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from functools32 import lru_cache\n",
    "wnl = WordNetLemmatizer()\n",
    "lemmatize = lru_cache(maxsize=50000)(wnl.lemmatize)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "def lemmatizer(text):        \n",
    "    sent = []\n",
    "    doc = nlp(text)\n",
    "    for word in doc:\n",
    "        sent.append(word.lemma_)\n",
    "    return \" \".join(sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>biden let illegal immigrant enter our country ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>if you re in a position to donate blood please...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the biden admin be sit on   covid test while p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>biden have the audacity to go on a reckless sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gopoversight dr fauci shut down debate about t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content\n",
       "0  biden let illegal immigrant enter our country ...\n",
       "1  if you re in a position to donate blood please...\n",
       "2  the biden admin be sit on   covid test while p...\n",
       "3  biden have the audacity to go on a reckless sp...\n",
       "4  gopoversight dr fauci shut down debate about t..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tweets_clean = pd.DataFrame(all_tweets_clean.Content.apply(lambda x: lemmatizer(x)))\n",
    "all_tweets_clean['Content'] = all_tweets_clean['Content'].str.replace('-PRON-', '')\n",
    "all_tweets_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54128</th>\n",
       "      <td>one wisconsin senator I vote to deliver   mill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54129</th>\n",
       "      <td>this be a horrible tragedy that demand a thoro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54130</th>\n",
       "      <td>I be proud to announce that wisconsin be recei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54131</th>\n",
       "      <td>reshadhudson senatorbaldwin react to supreme c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54132</th>\n",
       "      <td>shout out to milwaukee bronzeville neighborhoo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Content\n",
       "54128  one wisconsin senator I vote to deliver   mill...\n",
       "54129  this be a horrible tragedy that demand a thoro...\n",
       "54130  I be proud to announce that wisconsin be recei...\n",
       "54131  reshadhudson senatorbaldwin react to supreme c...\n",
       "54132  shout out to milwaukee bronzeville neighborhoo..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Lemmatize Dem Tweet data\n",
    "dem_clean = pd.DataFrame(dem_clean.Content.apply(lambda x: lemmatizer(x)))\n",
    "dem_clean['Content'] = dem_clean['Content'].str.replace('-PRON-', '')\n",
    "dem_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>biden let illegal immigrant enter our country ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>if you re in a position to donate blood please...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the biden admin be sit on   covid test while p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>biden have the audacity to go on a reckless sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gopoversight dr fauci shut down debate about t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content\n",
       "0  biden let illegal immigrant enter our country ...\n",
       "1  if you re in a position to donate blood please...\n",
       "2  the biden admin be sit on   covid test while p...\n",
       "3  biden have the audacity to go on a reckless sp...\n",
       "4  gopoversight dr fauci shut down debate about t..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Lemmatize Gop Tweet data\n",
    "gop_clean = pd.DataFrame(gop_clean.Content.apply(lambda x: lemmatizer(x)))\n",
    "gop_clean['Content'] = gop_clean['Content'].str.replace('-PRON-', '')\n",
    "gop_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write out port-lemmatization data \n",
    "dem_clean.to_csv('data/dem_clean.csv', encoding='utf-8', index=False)\n",
    "gop_clean.to_csv('data/gop_clean.csv', encoding='utf-8', index=False)\n",
    "all_tweets_clean.to_csv('data/all_tweets_clean.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## n-grams\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "'''\n",
    "def get_n_gram(corpus, n=None):\n",
    "    vec = CountVectorizer(stop_words=set(stop_words)).fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "'''\n",
    "def get_n_gram(corpus, ng, n=None):\n",
    "    vec = CountVectorizer(stop_words=set(stop_words),ngram_range=ng).fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in      vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>small business</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>southern border</td>\n",
       "      <td>321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>american people</td>\n",
       "      <td>301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>man woman</td>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>united states</td>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vaccine mandate</td>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>year ago</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>proud join</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>border crisis</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>look forward</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            bigram  count\n",
       "0   small business    365\n",
       "1  southern border    321\n",
       "2  american people    301\n",
       "3        man woman    290\n",
       "4    united states    289\n",
       "5  vaccine mandate    261\n",
       "6         year ago    235\n",
       "7       proud join    234\n",
       "8    border crisis    233\n",
       "9     look forward    231"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Republican Bigrams\n",
    "common_words = get_n_gram(gop_clean.Content,(2,2), 10)\n",
    "bigrams = pd.DataFrame(common_words, columns = ['bigram' , 'count'])\n",
    "bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trigram</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>brave man woman</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>crisis southern border</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>supply chain crisis</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chinese communist party</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>colleague send letter</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>law enforcement officer</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>congressional art competition</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>high school student</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>look forward work</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>capitol police officer</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         trigram  count\n",
       "0                brave man woman     99\n",
       "1         crisis southern border     91\n",
       "2            supply chain crisis     78\n",
       "3        chinese communist party     69\n",
       "4          colleague send letter     56\n",
       "5        law enforcement officer     53\n",
       "6  congressional art competition     53\n",
       "7            high school student     52\n",
       "8              look forward work     50\n",
       "9         capitol police officer     49"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Republican Trigrams\n",
    "common_words = get_n_gram(gop_clean.Content,(3,3), 10)\n",
    "trigram = pd.DataFrame(common_words, columns = ['trigram' , 'count'])\n",
    "trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trigram</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bipartisan infrastructure</td>\n",
       "      <td>2592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>health care</td>\n",
       "      <td>2504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>year ago</td>\n",
       "      <td>2453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>buildbackbetter act</td>\n",
       "      <td>1796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>small business</td>\n",
       "      <td>1778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>american rescue</td>\n",
       "      <td>1763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rescue plan</td>\n",
       "      <td>1759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>make sure</td>\n",
       "      <td>1641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>climate change</td>\n",
       "      <td>1585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>child care</td>\n",
       "      <td>1581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     trigram  count\n",
       "0  bipartisan infrastructure   2592\n",
       "1                health care   2504\n",
       "2                   year ago   2453\n",
       "3        buildbackbetter act   1796\n",
       "4             small business   1778\n",
       "5            american rescue   1763\n",
       "6                rescue plan   1759\n",
       "7                  make sure   1641\n",
       "8             climate change   1585\n",
       "9                 child care   1581"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Democrat Bigrams\n",
    "common_words = get_n_gram(dem_clean.Content,(2,2), 10)\n",
    "trigram = pd.DataFrame(common_words, columns = ['trigram' , 'count'])\n",
    "trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trigram</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>american rescue plan</td>\n",
       "      <td>1707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>child tax credit</td>\n",
       "      <td>1273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bipartisan infrastructure law</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>john lewis voting</td>\n",
       "      <td>496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>infrastructure investment jobs</td>\n",
       "      <td>455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>investment jobs act</td>\n",
       "      <td>455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lewis voting rights</td>\n",
       "      <td>421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>telephone town hall</td>\n",
       "      <td>399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bipartisan infrastructure deal</td>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>look forward work</td>\n",
       "      <td>321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          trigram  count\n",
       "0            american rescue plan   1707\n",
       "1                child tax credit   1273\n",
       "2   bipartisan infrastructure law    566\n",
       "3               john lewis voting    496\n",
       "4  infrastructure investment jobs    455\n",
       "5             investment jobs act    455\n",
       "6             lewis voting rights    421\n",
       "7             telephone town hall    399\n",
       "8  bipartisan infrastructure deal    383\n",
       "9               look forward work    321"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Democrat Trigrams\n",
    "common_words = get_n_gram(dem_clean.Content,(3,3), 10)\n",
    "trigram = pd.DataFrame(common_words, columns = ['trigram' , 'count'])\n",
    "trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trigram</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>american rescue plan</td>\n",
       "      <td>1729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>child tax credit</td>\n",
       "      <td>1282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bipartisan infrastructure law</td>\n",
       "      <td>573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>john lewis voting</td>\n",
       "      <td>503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>infrastructure investment jobs</td>\n",
       "      <td>462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>investment jobs act</td>\n",
       "      <td>462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>telephone town hall</td>\n",
       "      <td>433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lewis voting rights</td>\n",
       "      <td>427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bipartisan infrastructure deal</td>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>look forward work</td>\n",
       "      <td>371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          trigram  count\n",
       "0            american rescue plan   1729\n",
       "1                child tax credit   1282\n",
       "2   bipartisan infrastructure law    573\n",
       "3               john lewis voting    503\n",
       "4  infrastructure investment jobs    462\n",
       "5             investment jobs act    462\n",
       "6             telephone town hall    433\n",
       "7             lewis voting rights    427\n",
       "8  bipartisan infrastructure deal    390\n",
       "9               look forward work    371"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All tweet Trigrams\n",
    "common_words = get_n_gram(all_tweets_clean.Content,(3,3), 10)\n",
    "trigram = pd.DataFrame(common_words, columns = ['trigram' , 'count'])\n",
    "trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def remove_emoji(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\U00010000-\\U0010ffff\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u200d\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\ufe0f\"  # dingbats\n",
    "                               u\"\\u3030\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string)\n",
    "\n",
    "def removeRT(text):\n",
    "    RTless = lambda x: re.compile(r'\\#').sub('', re.compile('RT @').sub('@', x, count=1).strip())\n",
    "    return (RTless(text))\n",
    "\n",
    "def clean_text(text):\n",
    "    \n",
    "    # Remove RT\n",
    "    text = removeRT(text)\n",
    "    \n",
    "    # Remove emojis\n",
    "    text = remove_emoji(text)\n",
    "    \n",
    "    # Remove mentions\n",
    "    text = re.sub(\"@[A-Za-z0-9_]+\",\"\", text)\n",
    "    \n",
    "    # Remove Hastags\n",
    "    text = re.sub(\"#[A-Za-z0-9_]+\",\"\", text)\n",
    "    \n",
    "    # Make lowercase   \n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove text in square brackets\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "    \n",
    "    # Remove punctuation   \n",
    "    text = re.sub(r'[%s]' % re.escape(string.punctuation), '', text) \n",
    "    \n",
    "    # Remove words containing numbers\n",
    "    text = re.sub(r'\\w*\\d\\w*', '', text)\n",
    "    \n",
    "    # Remove Stopwords\n",
    "    text = text.split()\n",
    "    text = [w for w in text if not w in stopwords.words('english')]\n",
    "    text = \" \".join(word for word in text)    \n",
    "    \n",
    "    \n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf.Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "def remove_emoji(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\U00010000-\\U0010ffff\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u200d\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\ufe0f\"  # dingbats\n",
    "                               u\"\\u3030\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string)\n",
    "\n",
    "def removeRT(text):\n",
    "    RTless = lambda x: re.compile(r'\\#').sub('', re.compile('RT @').sub('@', x, count=1).strip())\n",
    "    return (RTless(text))\n",
    "\n",
    "def clean_text(text):\n",
    "    \n",
    "    # Remove RT\n",
    "    text = removeRT(text)\n",
    "    \n",
    "    # Remove emojis\n",
    "    text = remove_emoji(text)\n",
    "    \n",
    "    # Remove mentions\n",
    "    text = re.sub(\"@[A-Za-z0-9_]+\",\"\", text)\n",
    "    \n",
    "    # Remove Hastags\n",
    "    text = re.sub(\"#[A-Za-z0-9_]+\",\"\", text)\n",
    "    \n",
    "    # Make lowercase   \n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove text in square brackets\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "    \n",
    "    # Remove punctuation   \n",
    "    text = re.sub(r'[%s]' % re.escape(string.punctuation), '', text) \n",
    "    \n",
    "    # Remove words containing numbers\n",
    "    text = re.sub(r'\\w*\\d\\w*', '', text)\n",
    "    \n",
    "    # Remove Stopwords\n",
    "    text = text.split()\n",
    "    text = [w for w in text if not w in stopwords.words('english')]\n",
    "    text = \" \".join(word for word in text)    \n",
    "    \n",
    "    \n",
    "    return text\n",
    "\n",
    "testdf_clean = pd.DataFrame(testdf.Content.apply(lambda x: clean_text(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cleaning all tweets data (combined GOP and Dem)\n",
    "testdf_clean = pd.DataFrame(testdf.Content.apply(lambda x: clean_text(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cleaning GOP tweets data \n",
    "clean_gop_tweets = pd.DataFrame(just_gop_df.Content.apply(lambda x: clean_text(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cleaning Dem tweets data \n",
    "clean_dem_tweets = pd.DataFrame(just_dem_df.Content.apply(lambda x: clean_text(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reality Check: Size of Corpus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_corpus = tweets_df_clean.text\n",
    "\n",
    "corpuslen = sum([len(d.split(' ')) for d in word_corpus]) \n",
    "print(f'Total words in corpus: {corpuslen}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_core_web_sm\n",
    "\n",
    "nlp = en_core_web_sm.load()\n",
    "def lemmatizer(text):        \n",
    "    sent = []\n",
    "    doc = nlp(text)\n",
    "    for word in doc:\n",
    "        sent.append(word.lemma_)\n",
    "    return \" \".join(sent)\n",
    "tweets_df_clean = pd.DataFrame(tweets_df_clean.text.apply(lambda x: lemmatizer(x)))\n",
    "tweets_df_clean['text'] = tweets_df_clean['text'].str.replace('-PRON-', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functionalized NLP pipeline\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "def getTopics(df, min_df, max_df, max_features):\n",
    "    \n",
    "    ## Vectorization\n",
    "    vectorizer = CountVectorizer(\n",
    "        analyzer='word',       \n",
    "        min_df=min_df,# minimum required occurences of a word \n",
    "        #max_df=.7,# maximum required occurences of a word \n",
    "        stop_words=set(stop_words),# remove stop words\n",
    "        lowercase=True,# convert all words to lowercase\n",
    "        token_pattern='[a-zA-Z0-9]{3,}',# num chars > 3\n",
    "        max_features=max_features # max number of unique words\n",
    "        )\n",
    "    \n",
    "    data_matrix = vectorizer.fit_transform(df.text)\n",
    "    \n",
    "    ## Modeling\n",
    "    lda_model = LatentDirichletAllocation(\n",
    "    n_components=10, # Number of topics\n",
    "    learning_method='online',\n",
    "    random_state=20,       \n",
    "    n_jobs = -1  # Use all available CPUs\n",
    "                                        )\n",
    "    lda_output = lda_model.fit_transform(data_matrix)    \n",
    "    \n",
    "    return lda_model, vectorizer, data_matrix, lda_output\n",
    "\n",
    "\n",
    "lda_model, vectorizer, data_matrix, lda_output = getTopics(tweets_df_clean, min_df=3, max_df=.7, max_features=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.sklearn.prepare(lda_model, data_matrix, vectorizer, mds='tsne')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List Top 10 Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,topic in enumerate(lda_model.components_):\n",
    "    print(f'Top 10 words for topic #{i}:')\n",
    "    print([vectorizer.get_feature_names()[i] for i in topic.argsort()[-10:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at Unigrams, Bigrams and Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Unigrams\n",
    "#from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "def get_top_n_words(corpus, n=None):\n",
    "    vec = CountVectorizer(stop_words=set(stop_words)).fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "common_words = get_top_n_words(tweets_df_clean.text, 10)\n",
    "unigram = pd.DataFrame(common_words, columns = ['unigram' , 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## bigrams\n",
    "def get_top_n_bigram(corpus, n=None):\n",
    "    vec = CountVectorizer(stop_words=set(stop_words),ngram_range=(2,2)).fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in      vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "common_words = get_top_n_bigram(tweets_df_clean.text, 10)\n",
    "bigram = pd.DataFrame(common_words, columns = ['bigram' , 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## trigrams\n",
    "def get_top_n_trigram(corpus, n=None):\n",
    "    vec = CountVectorizer(stop_words=set(stop_words),ngram_range=(3,3)).fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in      vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "common_words = get_top_n_trigram(tweets_df_clean.text, 10)\n",
    "trigram = pd.DataFrame(common_words, columns = ['trigram' , 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
