{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using NLP to Determine the 2022 U.S. Midterm Elections Political Platforms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# importing libraries\n",
    "\n",
    "import configparser\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "\n",
    "import tweepy\n",
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "new_stopwords = ['amp','biden','know','say','today','start','week','want','day','talk','new','thank','birthday','wish','happy','discuss']\n",
    "stopwords.extend(new_stopwords)\n",
    "\n",
    "import spacy \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction import text \n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(new_stopwords)\n",
    "\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "\n",
    "\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Twitter API connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# login to twitter dev account\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "\n",
    "\n",
    "\n",
    "api_key = config['twitter']['api_key']\n",
    "api_key_secret = config['twitter']['api_key_secret']\n",
    "\n",
    "access_token = config['twitter']['access_token']\n",
    "access_token_secret = config['twitter']['access_token_secret']\n",
    "\n",
    "\n",
    "# aunthenticate\n",
    "\n",
    "auth = tweepy.OAuthHandler(api_key, api_key_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reality Check! \n",
    "## Pull 200 HouseDemocrat tweets to test connection\n",
    "posts = api.user_timeline(screen_name = \"HouseDemocrats\", count=200, tweet_mode=\"extended\")\n",
    "\n",
    "\n",
    "tweets = []\n",
    "columns=['user','text','date','favs','retweets']\n",
    "for tweet in posts:\n",
    "    tweets.append([tweet.user.screen_name, tweet.full_text, tweet.created_at, tweet.favorite_count, tweet.retweet_count])\n",
    "\n",
    "dftweets = pd.DataFrame(tweets, columns=columns)    \n",
    "dftweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in list of congress twitter users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "senate = pd.read_excel(open('data/congress_twitter.xlsx', 'rb'),\n",
    "              sheet_name='Senate')  \n",
    "house = pd.read_excel(open('data/congress_twitter.xlsx', 'rb'),\n",
    "              sheet_name='House')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting all Dem accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "senate_dems = senate[senate['Party ']=='D']\n",
    "house_dems  = house[house['Party']=='D']\n",
    "all_dems_df = pd.concat([senate_dems,house_dems])\n",
    "\n",
    "\n",
    "all_dems_df = all_dems_df.drop(all_dems_df.columns[[2,3,4,5]], axis=1)  # df.columns is zero-based pd.Index\n",
    "all_dems_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dems_df['Party']='D' \n",
    "all_dems_df['Acct']= all_dems_df['Link'].str.replace('https://twitter.com/','',regex=True)\n",
    "all_dems_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting all GOP Accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "senate_gop = senate[senate['Party ']=='R']\n",
    "house_gop  = house[house['Party']=='R']\n",
    "all_gop_df = pd.concat([senate_gop,house_gop])\n",
    "\n",
    "\n",
    "all_gop_df = all_gop_df.drop(all_gop_df.columns[[2,3,4,5]], axis=1)  # df.columns is zero-based pd.Index\n",
    "all_gop_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_gop_df['Party']='R' \n",
    "all_gop_df['Acct'] = all_gop_df['Link'].str.replace('https://twitter.com/','',regex=True)\n",
    "all_gop_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create combined list of accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create combined list of accounts\n",
    "all_congress_accounts = pd.concat([all_gop_df,all_dems_df])\n",
    "all_congress_accounts.to_csv('data/cong_accounts.csv', encoding='utf-8', index=False)\n",
    "all_congress_accounts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get 1000 recent tweets from user\n",
    "\n",
    "def get_1k_Tweets(user):\n",
    "    \n",
    "    tweets = []\n",
    "    columns=['User','Content','Date','Favs','RTs']\n",
    "        \n",
    "    for tweet in tweepy.Cursor(api.user_timeline,screen_name=user).items(1000):\n",
    "        tweets.append([tweet.user.screen_name, \n",
    "                       tweet.text, \n",
    "                       tweet.created_at, \n",
    "                       tweet.favorite_count, \n",
    "                       tweet.retweet_count])\n",
    "    tempdf = pd.DataFrame(tweets, columns=columns)\n",
    "    return tempdf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_congress_tweets = pd.DataFrame()\n",
    "#all_congress_tweets  = pd.DataFrame()#\n",
    "no_accts = []\n",
    "for cong in tqdm(all_congress_accounts[214:].Acct):\n",
    "    try:\n",
    "        temp_tweets = get_1k_Tweets(cong)\n",
    "        all_congress_tweets = pd.concat([all_congress_tweets,temp_tweets])\n",
    "    except:\n",
    "        no_accts.append(cong)\n",
    "        print(f'{cong} account is not active or does not have tweets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_accts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_congress_tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_congress_tweets.to_csv('data/all_cong_tweets_01012021_01162022.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_congress_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_congress_accounts.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get Political Party and Name of account \n",
    "full_Cong_df = pd.merge(all_congress_tweets,all_congress_accounts, left_on='User', right_on='Acct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove redundant columns (link and Acct)\n",
    "full_Cong_df.drop(['Link','Acct'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_Cong_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write out full dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_Cong_df.to_csv('data/all_party_tweets_01012021_01162022.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_Cong_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 318055 entries, 0 to 318054\n",
      "Data columns (total 7 columns):\n",
      " #   Column   Non-Null Count   Dtype \n",
      "---  ------   --------------   ----- \n",
      " 0   User     314055 non-null  object\n",
      " 1   Content  318055 non-null  object\n",
      " 2   Date     318055 non-null  object\n",
      " 3   Favs     318055 non-null  int64 \n",
      " 4   RTs      318055 non-null  int64 \n",
      " 5   Name     318055 non-null  object\n",
      " 6   Party    318055 non-null  object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 17.0+ MB\n"
     ]
    }
   ],
   "source": [
    "all_congress_tweets = pd.read_csv('data/all_party_tweets_01012021_01162022.csv')\n",
    "all_congress_tweets.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restrict tweets to 2021-2022\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 266955 entries, 0 to 317693\n",
      "Data columns (total 7 columns):\n",
      " #   Column   Non-Null Count   Dtype \n",
      "---  ------   --------------   ----- \n",
      " 0   User     262955 non-null  object\n",
      " 1   Content  266955 non-null  object\n",
      " 2   Date     266955 non-null  object\n",
      " 3   Favs     266955 non-null  int64 \n",
      " 4   RTs      266955 non-null  int64 \n",
      " 5   Name     266955 non-null  object\n",
      " 6   Party    266955 non-null  object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 16.3+ MB\n"
     ]
    }
   ],
   "source": [
    "## Filter dates from 2021-2022\n",
    "\n",
    "start_date = '2021-01-01 00:00:00+00:00'\n",
    "end_date   = '2022-01-20 00:00:00+00:00'\n",
    "mask = (all_congress_tweets['Date'] > start_date) & (all_congress_tweets['Date'] <= end_date)\n",
    "\n",
    "all_tweets= all_congress_tweets.loc[mask]\n",
    "all_tweets.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate Dem and GOP Tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 38782 entries, 0 to 53963\n",
      "Data columns (total 7 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   User     34782 non-null  object\n",
      " 1   Content  38782 non-null  object\n",
      " 2   Date     38782 non-null  object\n",
      " 3   Favs     38782 non-null  int64 \n",
      " 4   RTs      38782 non-null  int64 \n",
      " 5   Name     38782 non-null  object\n",
      " 6   Party    38782 non-null  object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "just_gop_df = all_tweets[all_tweets.Party=='R']\n",
    "just_gop_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 228173 entries, 54128 to 317693\n",
      "Data columns (total 7 columns):\n",
      " #   Column   Non-Null Count   Dtype \n",
      "---  ------   --------------   ----- \n",
      " 0   User     228173 non-null  object\n",
      " 1   Content  228173 non-null  object\n",
      " 2   Date     228173 non-null  object\n",
      " 3   Favs     228173 non-null  int64 \n",
      " 4   RTs      228173 non-null  int64 \n",
      " 5   Name     228173 non-null  object\n",
      " 6   Party    228173 non-null  object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 13.9+ MB\n"
     ]
    }
   ],
   "source": [
    "just_dem_df = all_tweets[all_tweets.Party=='D']\n",
    "just_dem_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testdf = all_tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emoji(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\U00010000-\\U0010ffff\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u200d\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\ufe0f\"  # dingbats\n",
    "                               u\"\\u3030\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string)\n",
    "\n",
    "\n",
    "def removeRT(text):\n",
    "    RTless = lambda x: re.compile(r'\\#').sub('', re.compile('RT @').sub('@', x, count=1).strip())\n",
    "    return (RTless(text))\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove RT\n",
    "    text = removeRT(text)\n",
    "    \n",
    "    # Remove emojis\n",
    "    text = remove_emoji(text)\n",
    "\n",
    "    #Make text lowercase   \n",
    "    text = text.lower()\n",
    "    \n",
    "    #remove text in square brackets\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "    \n",
    "    #remove punctuation   \n",
    "    text = re.sub(r'[%s]' % re.escape(string.punctuation), '', text) \n",
    "    \n",
    "    #remove words containing numbers\n",
    "    text = re.sub(r'\\w*\\d\\w*', '', text)\n",
    "    \n",
    "\n",
    "    \n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testdf_clean = pd.DataFrame(testdf.Content.apply(lambda x: clean_text(x)))\n",
    "#testdf_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54128</th>\n",
       "      <td>one wisconsin senator me voted to deliver  mil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54129</th>\n",
       "      <td>this is a horrible tragedy that demands a thor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54130</th>\n",
       "      <td>i am proud to announce that wisconsin is recei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54131</th>\n",
       "      <td>reshadhudson senatorbaldwin reacts to supreme ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54132</th>\n",
       "      <td>shout out to milwaukees bronzeville neighborho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317689</th>\n",
       "      <td>is also bringing us the continued dominance o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317690</th>\n",
       "      <td>congratulations to ukfootball on their taxslay...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317691</th>\n",
       "      <td>i feel compelled to note that the senate major...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317692</th>\n",
       "      <td>if mitch doesn’t want to send out  checks to a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317693</th>\n",
       "      <td>wishing everyone a happy healthy and peaceful ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>228173 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Content\n",
       "54128   one wisconsin senator me voted to deliver  mil...\n",
       "54129   this is a horrible tragedy that demands a thor...\n",
       "54130   i am proud to announce that wisconsin is recei...\n",
       "54131   reshadhudson senatorbaldwin reacts to supreme ...\n",
       "54132   shout out to milwaukees bronzeville neighborho...\n",
       "...                                                   ...\n",
       "317689   is also bringing us the continued dominance o...\n",
       "317690  congratulations to ukfootball on their taxslay...\n",
       "317691  i feel compelled to note that the senate major...\n",
       "317692  if mitch doesn’t want to send out  checks to a...\n",
       "317693  wishing everyone a happy healthy and peaceful ...\n",
       "\n",
       "[228173 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Clean Dem Tweets\n",
    "dem_clean = pd.DataFrame(just_dem_df.Content.apply(lambda x: clean_text(x)))\n",
    "dem_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>biden let illegal immigrants enter our country...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>if youre in a position to donate blood please ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the biden admin is sitting on  covid tests whi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>biden had the audacity to go on a reckless spe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gopoversight dr fauci shut down debate about t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53959</th>\n",
       "      <td>pursuant to the us constitution state legislat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53960</th>\n",
       "      <td>in battleground states signature verification ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53961</th>\n",
       "      <td>usarmy selfless service  \\n\\nsunrise at arling...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53962</th>\n",
       "      <td>richardgrenell washington is so out of touch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53963</th>\n",
       "      <td>wishing you and your loved ones a happy and sa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38782 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Content\n",
       "0      biden let illegal immigrants enter our country...\n",
       "1      if youre in a position to donate blood please ...\n",
       "2      the biden admin is sitting on  covid tests whi...\n",
       "3      biden had the audacity to go on a reckless spe...\n",
       "4      gopoversight dr fauci shut down debate about t...\n",
       "...                                                  ...\n",
       "53959  pursuant to the us constitution state legislat...\n",
       "53960  in battleground states signature verification ...\n",
       "53961  usarmy selfless service  \\n\\nsunrise at arling...\n",
       "53962       richardgrenell washington is so out of touch\n",
       "53963  wishing you and your loved ones a happy and sa...\n",
       "\n",
       "[38782 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Clean Gop Tweets\n",
    "gop_clean = pd.DataFrame(just_gop_df.Content.apply(lambda x: clean_text(x)))\n",
    "gop_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>biden let illegal immigrants enter our country...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>if youre in a position to donate blood please ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the biden admin is sitting on  covid tests whi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>biden had the audacity to go on a reckless spe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gopoversight dr fauci shut down debate about t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317689</th>\n",
       "      <td>is also bringing us the continued dominance o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317690</th>\n",
       "      <td>congratulations to ukfootball on their taxslay...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317691</th>\n",
       "      <td>i feel compelled to note that the senate major...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317692</th>\n",
       "      <td>if mitch doesn’t want to send out  checks to a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317693</th>\n",
       "      <td>wishing everyone a happy healthy and peaceful ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>266955 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Content\n",
       "0       biden let illegal immigrants enter our country...\n",
       "1       if youre in a position to donate blood please ...\n",
       "2       the biden admin is sitting on  covid tests whi...\n",
       "3       biden had the audacity to go on a reckless spe...\n",
       "4       gopoversight dr fauci shut down debate about t...\n",
       "...                                                   ...\n",
       "317689   is also bringing us the continued dominance o...\n",
       "317690  congratulations to ukfootball on their taxslay...\n",
       "317691  i feel compelled to note that the senate major...\n",
       "317692  if mitch doesn’t want to send out  checks to a...\n",
       "317693  wishing everyone a happy healthy and peaceful ...\n",
       "\n",
       "[266955 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Clean all combined tweets\n",
    "all_tweets_clean = pd.DataFrame(all_tweets.Content.apply(lambda x: clean_text(x)))\n",
    "all_tweets_clean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization to get word roots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lemmatization \n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "def lemmatizer(text):        \n",
    "    sent = []\n",
    "    doc = nlp(text)\n",
    "    for word in doc:\n",
    "        sent.append(word.lemma_)\n",
    "    return \" \".join(sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets_clean = pd.DataFrame(all_tweets_clean.Content.apply(lambda x: lemmatizer(x)))\n",
    "all_tweets_clean['Content'] = all_tweets_clean['Content'].str.replace('-PRON-', '')\n",
    "all_tweets_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lemmatize Dem Tweet data\n",
    "dem_clean = pd.DataFrame(dem_clean.Content.apply(lambda x: lemmatizer(x)))\n",
    "dem_clean['Content'] = dem_clean['Content'].str.replace('-PRON-', '')\n",
    "dem_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lemmatize Gop Tweet data\n",
    "gop_clean = pd.DataFrame(gop_clean.Content.apply(lambda x: lemmatizer(x)))\n",
    "gop_clean['Content'] = gop_clean['Content'].str.replace('-PRON-', '')\n",
    "gop_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Unigrams\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "'''\n",
    "def get_n_gram(corpus, n=None):\n",
    "    vec = CountVectorizer(stop_words=set(stop_words)).fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "'''\n",
    "def get_n_gram(corpus, n=None,ng):\n",
    "    vec = CountVectorizer(stop_words=set(stop_words),ngram_range=ng).fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in      vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words = get_n_gram(gop_clean.text, 10,ng=(2,2))\n",
    "bigrams = pd.DataFrame(common_words, columns = ['bigram' , 'count'])\n",
    "bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def remove_emoji(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\U00010000-\\U0010ffff\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u200d\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\ufe0f\"  # dingbats\n",
    "                               u\"\\u3030\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string)\n",
    "\n",
    "def removeRT(text):\n",
    "    RTless = lambda x: re.compile(r'\\#').sub('', re.compile('RT @').sub('@', x, count=1).strip())\n",
    "    return (RTless(text))\n",
    "\n",
    "def clean_text(text):\n",
    "    \n",
    "    # Remove RT\n",
    "    text = removeRT(text)\n",
    "    \n",
    "    # Remove emojis\n",
    "    text = remove_emoji(text)\n",
    "    \n",
    "    # Remove mentions\n",
    "    text = re.sub(\"@[A-Za-z0-9_]+\",\"\", text)\n",
    "    \n",
    "    # Remove Hastags\n",
    "    text = re.sub(\"#[A-Za-z0-9_]+\",\"\", text)\n",
    "    \n",
    "    # Make lowercase   \n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove text in square brackets\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "    \n",
    "    # Remove punctuation   \n",
    "    text = re.sub(r'[%s]' % re.escape(string.punctuation), '', text) \n",
    "    \n",
    "    # Remove words containing numbers\n",
    "    text = re.sub(r'\\w*\\d\\w*', '', text)\n",
    "    \n",
    "    # Remove Stopwords\n",
    "    text = text.split()\n",
    "    text = [w for w in text if not w in stopwords.words('english')]\n",
    "    text = \" \".join(word for word in text)    \n",
    "    \n",
    "    \n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf.Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "def remove_emoji(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\U00010000-\\U0010ffff\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u200d\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\ufe0f\"  # dingbats\n",
    "                               u\"\\u3030\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string)\n",
    "\n",
    "def removeRT(text):\n",
    "    RTless = lambda x: re.compile(r'\\#').sub('', re.compile('RT @').sub('@', x, count=1).strip())\n",
    "    return (RTless(text))\n",
    "\n",
    "def clean_text(text):\n",
    "    \n",
    "    # Remove RT\n",
    "    text = removeRT(text)\n",
    "    \n",
    "    # Remove emojis\n",
    "    text = remove_emoji(text)\n",
    "    \n",
    "    # Remove mentions\n",
    "    text = re.sub(\"@[A-Za-z0-9_]+\",\"\", text)\n",
    "    \n",
    "    # Remove Hastags\n",
    "    text = re.sub(\"#[A-Za-z0-9_]+\",\"\", text)\n",
    "    \n",
    "    # Make lowercase   \n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove text in square brackets\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "    \n",
    "    # Remove punctuation   \n",
    "    text = re.sub(r'[%s]' % re.escape(string.punctuation), '', text) \n",
    "    \n",
    "    # Remove words containing numbers\n",
    "    text = re.sub(r'\\w*\\d\\w*', '', text)\n",
    "    \n",
    "    # Remove Stopwords\n",
    "    text = text.split()\n",
    "    text = [w for w in text if not w in stopwords.words('english')]\n",
    "    text = \" \".join(word for word in text)    \n",
    "    \n",
    "    \n",
    "    return text\n",
    "\n",
    "testdf_clean = pd.DataFrame(testdf.Content.apply(lambda x: clean_text(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cleaning all tweets data (combined GOP and Dem)\n",
    "testdf_clean = pd.DataFrame(testdf.Content.apply(lambda x: clean_text(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cleaning GOP tweets data \n",
    "clean_gop_tweets = pd.DataFrame(just_gop_df.Content.apply(lambda x: clean_text(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cleaning Dem tweets data \n",
    "clean_dem_tweets = pd.DataFrame(just_dem_df.Content.apply(lambda x: clean_text(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reality Check: Size of Corpus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_corpus = tweets_df_clean.text\n",
    "\n",
    "corpuslen = sum([len(d.split(' ')) for d in word_corpus]) \n",
    "print(f'Total words in corpus: {corpuslen}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_core_web_sm\n",
    "\n",
    "nlp = en_core_web_sm.load()\n",
    "def lemmatizer(text):        \n",
    "    sent = []\n",
    "    doc = nlp(text)\n",
    "    for word in doc:\n",
    "        sent.append(word.lemma_)\n",
    "    return \" \".join(sent)\n",
    "tweets_df_clean = pd.DataFrame(tweets_df_clean.text.apply(lambda x: lemmatizer(x)))\n",
    "tweets_df_clean['text'] = tweets_df_clean['text'].str.replace('-PRON-', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functionalized NLP pipeline\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "def getTopics(df, min_df, max_df, max_features):\n",
    "    \n",
    "    ## Vectorization\n",
    "    vectorizer = CountVectorizer(\n",
    "        analyzer='word',       \n",
    "        min_df=min_df,# minimum required occurences of a word \n",
    "        #max_df=.7,# maximum required occurences of a word \n",
    "        stop_words=set(stop_words),# remove stop words\n",
    "        lowercase=True,# convert all words to lowercase\n",
    "        token_pattern='[a-zA-Z0-9]{3,}',# num chars > 3\n",
    "        max_features=max_features # max number of unique words\n",
    "        )\n",
    "    \n",
    "    data_matrix = vectorizer.fit_transform(df.text)\n",
    "    \n",
    "    ## Modeling\n",
    "    lda_model = LatentDirichletAllocation(\n",
    "    n_components=10, # Number of topics\n",
    "    learning_method='online',\n",
    "    random_state=20,       \n",
    "    n_jobs = -1  # Use all available CPUs\n",
    "                                        )\n",
    "    lda_output = lda_model.fit_transform(data_matrix)    \n",
    "    \n",
    "    return lda_model, vectorizer, data_matrix, lda_output\n",
    "\n",
    "\n",
    "lda_model, vectorizer, data_matrix, lda_output = getTopics(tweets_df_clean, min_df=3, max_df=.7, max_features=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.sklearn.prepare(lda_model, data_matrix, vectorizer, mds='tsne')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List Top 10 Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,topic in enumerate(lda_model.components_):\n",
    "    print(f'Top 10 words for topic #{i}:')\n",
    "    print([vectorizer.get_feature_names()[i] for i in topic.argsort()[-10:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at Unigrams, Bigrams and Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Unigrams\n",
    "#from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "def get_top_n_words(corpus, n=None):\n",
    "    vec = CountVectorizer(stop_words=set(stop_words)).fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "common_words = get_top_n_words(tweets_df_clean.text, 10)\n",
    "unigram = pd.DataFrame(common_words, columns = ['unigram' , 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## bigrams\n",
    "def get_top_n_bigram(corpus, n=None):\n",
    "    vec = CountVectorizer(stop_words=set(stop_words),ngram_range=(2,2)).fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in      vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "common_words = get_top_n_bigram(tweets_df_clean.text, 10)\n",
    "bigram = pd.DataFrame(common_words, columns = ['bigram' , 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## trigrams\n",
    "def get_top_n_trigram(corpus, n=None):\n",
    "    vec = CountVectorizer(stop_words=set(stop_words),ngram_range=(3,3)).fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in      vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "common_words = get_top_n_trigram(tweets_df_clean.text, 10)\n",
    "trigram = pd.DataFrame(common_words, columns = ['trigram' , 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
